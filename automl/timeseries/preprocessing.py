# automl/timeseries/preprocessing.py

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.ensemble import IsolationForest

def auto_datetime(df, col):
    # datetime ë³€í™˜
    if pd.api.types.is_datetime64_any_dtype(df[col]):
        return df[col]
    converted = pd.to_datetime(df[col], errors="coerce", infer_datetime_format=True)
    n_missing = converted.isna().sum()
    if n_missing > 0:
        sample_vals = df[col][converted.isna()].astype(str).unique()[:5]
        st.warning(
            f"'{col}' ì»¬ëŸ¼ì„ datetimeìœ¼ë¡œ ë³€í™˜ ì‹¤íŒ¨: {n_missing}ê°œ NaT. ì˜ˆì‹œ: {sample_vals}"
        )
    return converted

def auto_numeric(series, colname=""):
    result = pd.to_numeric(series, errors='coerce')
    n_missing = result.isna().sum()
    if n_missing > 0:
        sample_vals = series[result.isna()].astype(str).unique()[:5]
        st.warning(
            f"[{colname}] ì»¬ëŸ¼ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜ ì‹¤íŒ¨: {n_missing}ê°œ NaN. ì˜ˆì‹œ: {sample_vals}"
        )
    return result

class TimeSeriesPreprocessor:
    def __init__(self):
        self.time_col = None
        self.num_cols = []
        self.cat_cols = []
        self.scaler = None
        self.selected_columns = []
        self.log = []

    def fit(self, df, time_col, target):
        self.log.clear()
        self.time_col = time_col

        # 1. ì‹œê°„ ì»¬ëŸ¼ robustí•˜ê²Œ ë³€í™˜ ë° ì •ë ¬
        df[time_col] = auto_datetime(df, time_col)
        if df[time_col].isna().sum() > 0:
            self.log.append(f"'{time_col}' ì»¬ëŸ¼ datetime ë³€í™˜ì—ì„œ {df[time_col].isna().sum()}ê°œ NaT ë°œìƒ")
        df = df.dropna(subset=[time_col]).sort_values(time_col).reset_index(drop=True)
        self.log.append("ì‹œê°„ìˆœìœ¼ë¡œ ë°ì´í„° ì •ë ¬")

        # 2. íƒ€ê¹ƒ í¬í•¨ ëª¨ë“  ìˆ˜ì¹˜í˜• robust ë³€í™˜ (objectâ†’float)
        if df[target].dtype == 'object':
            df[target] = auto_numeric(df[target], target)
        # ëª¨ë“  object â†’ numeric ì‹œë„
        for col in df.columns:
            if col in [time_col, target]:
                continue
            if df[col].dtype == "object":
                try:
                    df[col] = auto_numeric(df[col], col)
                except Exception as e:
                    st.warning(f"[{col}] ì»¬ëŸ¼ ë³€í™˜ ì—ëŸ¬: {e}")

        self.num_cols = [col for col in df.select_dtypes(include='number').columns if col != target]
        self.cat_cols = list(df.select_dtypes(include=['object', 'category']).columns)

        # 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (íƒ€ê¹ƒ: ë³´ê°„/ì±„ì›€, ìˆ˜ì¹˜: í‰ê· , ë²”ì£¼: ìµœë¹ˆ)
        if df[target].isna().sum() > 0:
            df[target] = df[target].interpolate(method="linear").fillna(method="bfill").fillna(method="ffill")
            self.log.append(f"íƒ€ê¹ƒ({target}) ê²°ì¸¡ì¹˜: ì„ í˜•ë³´ê°„ ë° ì–‘ë°©í–¥ ì±„ì›€")
        if self.num_cols:
            for col in self.num_cols:
                if df[col].isna().sum() > 0:
                    df[col] = df[col].interpolate(method="linear").fillna(method="bfill").fillna(method="ffill")
                    self.log.append(f"{col} ê²°ì¸¡ì¹˜: ì„ í˜•ë³´ê°„ ë° ì–‘ë°©í–¥ ì±„ì›€")
        else:
            self.log.append("ìˆ˜ì¹˜í˜• ê²°ì¸¡ ì—†ìŒ")
        if self.cat_cols:
            for col in self.cat_cols:
                if df[col].isna().sum() > 0:
                    mode_val = df[col].mode(dropna=True)[0] if not df[col].mode(dropna=True).empty else ""
                    df[col].fillna(mode_val, inplace=True)
                    self.log.append(f"{col}: ìµœë¹ˆê°’ '{mode_val}'ë¡œ ê²°ì¸¡ ëŒ€ì¹˜")
        else:
            self.log.append("ë²”ì£¼í˜• ê²°ì¸¡ ì—†ìŒ")

        # 4. ì¤‘ë³µ ì‹œê°„ ì œê±°
        dup_cnt = df.duplicated(subset=[time_col]).sum()
        if dup_cnt > 0:
            df = df.drop_duplicates(subset=[time_col], keep='last')
            self.log.append(f"ì¤‘ë³µ timestamp {dup_cnt}ê±´: ë§ˆì§€ë§‰ê°’ìœ¼ë¡œ ìë™ ì œê±°")
        else:
            self.log.append("ì¤‘ë³µ timestamp ì—†ìŒ")

        # 5. ì‹œê°„ íŒŒìƒ í”¼ì²˜
        if pd.api.types.is_datetime64_any_dtype(df[time_col]):
            df["month"] = df[time_col].dt.month.fillna(0).astype(int)
            df["weekday"] = df[time_col].dt.dayofweek.fillna(0).astype(int)
            df["hour"] = df[time_col].dt.hour.fillna(0).astype(int)
            df["is_weekend"] = (df["weekday"] >= 5).astype(int)
            self.log.append("month/weekday/hour/is_weekend íŒŒìƒ")
        else:
            for feat in ["month","weekday","hour","is_weekend"]:
                df[feat] = 0
            self.log.append("datetime ë³€í™˜ ì‹¤íŒ¨ë¡œ ì‹œê°„íŒŒìƒë³€ìˆ˜ 0 ì²˜ë¦¬")

        # 6. lag/rolling ìë™ ì¶”ê°€
        df["lag1"] = df[target].shift(1)
        df["lag7"] = df[target].shift(7)
        df["rolling_mean_7"] = df[target].rolling(7, min_periods=1).mean()
        df["rolling_std_7"] = df[target].rolling(7, min_periods=1).std().fillna(0)
        self.log.append("lag1, lag7, rolling_mean_7, rolling_std_7 ìƒì„±")

        # 7. ì´ìƒì¹˜ íƒì§€: IsolationForest
        X_num = df[self.num_cols + ["lag1", "lag7", "rolling_mean_7", "rolling_std_7"]].fillna(0)
        if len(df) > 200 and X_num.shape[1] > 0:
            iso = IsolationForest(n_estimators=40, contamination=0.01, random_state=42)
            out_pred = iso.fit_predict(X_num)
            outlier_idx = np.where(out_pred == -1)[0]
            if len(outlier_idx) > 0:
                df = df.drop(df.index[outlier_idx])
                self.log.append(f"IsolationForestë¡œ {len(outlier_idx)}ê°œ ì´ìƒì¹˜ ìë™ ì œê±°")
            else:
                self.log.append("ì‹¬ê°í•œ ì´ìƒì¹˜ ì—†ìŒ.")
        else:
            self.log.append("í–‰ ê°œìˆ˜ ë¶€ì¡±/ìˆ˜ì¹˜í˜• ë¶€ì¡±: ì´ìƒì¹˜ íƒì§€ ìƒëµ")

        # 8. ìŠ¤ì¼€ì¼ë§
        skewness = np.abs(df[self.num_cols]).skew().mean() if self.num_cols else 0
        if skewness < 1:
            self.scaler = StandardScaler()
            self.log.append(f"í‰ê·  Skewness {skewness:.2f}: 1 ë¯¸ë§Œ â†’ StandardScaler")
        else:
            self.scaler = RobustScaler()
            self.log.append(f"í‰ê·  Skewness {skewness:.2f}: 1 ì´ìƒ â†’ RobustScaler")

        scaled_num = self.scaler.fit_transform(df[self.num_cols + ["lag1", "lag7", "rolling_mean_7", "rolling_std_7"]].fillna(0))
        self.selected_columns = list(self.num_cols) + ["lag1", "lag7", "rolling_mean_7", "rolling_std_7", "month", "weekday", "hour", "is_weekend"]
        self.log.append(f"ìŠ¤ì¼€ì¼ë§ + ìµœì¢… ì…ë ¥ í”¼ì²˜: {', '.join(self.selected_columns)}")
        self.df_ref = df.copy()

    def transform(self, df, time_col, target):
        df[time_col] = auto_datetime(df, time_col)
        df = df.dropna(subset=[time_col]).sort_values(time_col).reset_index(drop=True)
        if df[target].dtype == 'object':
            df[target] = auto_numeric(df[target], target)
        for col in df.columns:
            if col in [time_col, target]:
                continue
            if df[col].dtype == "object":
                try:
                    df[col] = auto_numeric(df[col], col)
                except Exception:
                    continue
        # ì‹œê°„ íŒŒìƒ
        if pd.api.types.is_datetime64_any_dtype(df[time_col]):
            df["month"] = df[time_col].dt.month.fillna(0).astype(int)
            df["weekday"] = df[time_col].dt.dayofweek.fillna(0).astype(int)
            df["hour"] = df[time_col].dt.hour.fillna(0).astype(int)
            df["is_weekend"] = (df["weekday"] >= 5).astype(int)
        else:
            for feat in ["month","weekday","hour","is_weekend"]:
                df[feat] = 0
        # lag/rolling
        df["lag1"] = df[target].shift(1)
        df["lag7"] = df[target].shift(7)
        df["rolling_mean_7"] = df[target].rolling(7, min_periods=1).mean()
        df["rolling_std_7"] = df[target].rolling(7, min_periods=1).std().fillna(0)
        # ê²°ì¸¡ ë³´ê°„
        for col in self.selected_columns:
            if df[col].isna().sum() > 0:
                df[col] = df[col].interpolate(method="linear").fillna(method="bfill").fillna(method="ffill")
        # ìŠ¤ì¼€ì¼ë§
        X_num = df[self.num_cols + ["lag1", "lag7", "rolling_mean_7", "rolling_std_7"]].fillna(0)
        X_num_scaled = self.scaler.transform(X_num)
        X = pd.DataFrame(X_num_scaled, columns=self.num_cols + ["lag1", "lag7", "rolling_mean_7", "rolling_std_7"], index=df.index)
        X = pd.concat([X, df[["month", "weekday", "hour", "is_weekend"]].reset_index(drop=True)], axis=1)
        X = X[self.selected_columns]
        return X

    def fit_transform(self, df, time_col, target):
        self.fit(df, time_col, target)
        return self.transform(df, time_col, target), self.df_ref, self

    def get_log(self):
        return self.log

def run(df, target, time_col, mode="fit_transform", preprocessor=None):
    if mode == "fit_transform":
        pre = TimeSeriesPreprocessor()
        X, df_ref, pre = pre.fit_transform(df.copy(), time_col, target)
        st.header("âš¡ ì „ì²˜ë¦¬ ë‹¨ê³„ë³„ ì„¤ëª… (Train ê¸°ì¤€)")
        for step in pre.get_log():
            st.markdown(f"- {step}")
        st.subheader("ğŸ“‹ ì „ì²˜ë¦¬ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (Train)")
        st.write(X.head())
        st.write("ìµœì¢… shape:", X.shape)
        y = df[target].reset_index(drop=True)
        return X, y, pre
    elif mode == "transform" and preprocessor is not None:
        X = preprocessor.transform(df.copy(), time_col, target)
        st.header("âš¡ ì „ì²˜ë¦¬ ê²°ê³¼ (Valid/Test ê¸°ì¤€)")
        st.write("Trainì—ì„œ fitëœ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜(transform)ë§Œ ì ìš©")
        st.write(X.head())
        st.write("ìµœì¢… shape:", X.shape)
        return X
    else:
        raise ValueError("modeëŠ” fit_transform/transform ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•˜ê³ , transformì‹œ preprocessor í•„ìš”")