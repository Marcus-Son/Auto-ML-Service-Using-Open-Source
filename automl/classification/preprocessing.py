import streamlit as st
import numpy as np
import pandas as pd
import sklearn
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, LabelEncoder
from sklearn.utils import class_weight
from sklearn.ensemble import IsolationForest
from imblearn.over_sampling import SMOTE

class ClassificationPreprocessor:
    def __init__(self):
        self.num_cols = []
        self.cat_cols = []
        self.imputer_num = None
        self.imputer_cat = None
        self.scaler = None
        self.encoder = None
        self.class_weights = None
        self.selected_columns = []
        self.log = []
        self.smote_applied = False
        self.isolation_mask = None   # ì´ìƒì¹˜ ì œê±°ìš© ë§ˆìŠ¤í¬

    def fit(self, df, target):
        self.log.clear()
        # 1. ì»¬ëŸ¼ êµ¬ë¶„
        self.num_cols = [col for col in df.select_dtypes(include='number').columns if col != target]
        self.cat_cols = list(df.select_dtypes(include=['object', 'category']).columns)

        # 2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•: í‰ê· /ì¤‘ì•™ê°’, ë²”ì£¼í˜•: ìµœë¹ˆê°’)
        num_null_ratio = df[self.num_cols].isna().mean() if self.num_cols else pd.Series()
        cat_null_ratio = df[self.cat_cols].isna().mean() if self.cat_cols else pd.Series()
        # ìˆ˜ì¹˜í˜•
        for col in self.num_cols:
            null_ratio = num_null_ratio[col]
            if null_ratio == 0:
                continue
            if null_ratio < 0.3:
                strategy = "mean"
                reason = f"{col} ê²°ì¸¡ì¹˜ {null_ratio:.1%}: 30% ë¯¸ë§Œ â†’ í‰ê·  ëŒ€ì¹˜"
            else:
                strategy = "median"
                reason = f"{col} ê²°ì¸¡ì¹˜ {null_ratio:.1%}: 30% ì´ìƒ â†’ ì¤‘ì•™ê°’ ëŒ€ì¹˜"
            self.log.append(reason)
        self.imputer_num = SimpleImputer(strategy="mean")
        self.imputer_num.fit(df[self.num_cols])
        self.log.append("ìˆ˜ì¹˜í˜• ê²°ì¸¡ì¹˜: í‰ê· (mean)ìœ¼ë¡œ ì¼ê´„ ëŒ€ì¹˜ (SimpleImputer).")
        # ë²”ì£¼í˜•
        if self.cat_cols:
            self.imputer_cat = SimpleImputer(strategy="most_frequent")
            self.imputer_cat.fit(df[self.cat_cols])
            self.log.append("ë²”ì£¼í˜• ê²°ì¸¡ì¹˜: ìµœë¹ˆê°’(most_frequent)ìœ¼ë¡œ ëŒ€ì¹˜ (SimpleImputer).")
        else:
            self.imputer_cat = None
            self.log.append("ë²”ì£¼í˜• ë³€ìˆ˜ ì—†ìŒ â†’ ê²°ì¸¡ ëŒ€ì¹˜ ìƒëµ.")

        # 3. ìŠ¤ì¼€ì¼ë§: ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì— ëŒ€í•´ ë¶„í¬ í™•ì¸ í›„ ì ìš©
        skewness = np.abs(df[self.num_cols].skew()).mean() if self.num_cols else 0
        if skewness < 1:
            self.scaler = StandardScaler()
            self.log.append(f"í‰ê·  Skewness {skewness:.2f}: 1 ë¯¸ë§Œ â†’ StandardScaler ì ìš© (ì •ê·œë¶„í¬ ê°€ì •).")
        else:
            self.scaler = RobustScaler()
            self.log.append(f"í‰ê·  Skewness {skewness:.2f}: 1 ì´ìƒ â†’ RobustScaler ì ìš© (ì´ìƒì¹˜ ì˜í–¥ ìµœì†Œí™”).")
        num_filled = pd.DataFrame(self.imputer_num.transform(df[self.num_cols]), columns=self.num_cols, index=df.index)
        self.scaler.fit(num_filled)

        # 4. ì¸ì½”ë”©: ë²”ì£¼í˜• ë³€ìˆ˜ ì „ì²´ OneHotEncoder
        if self.cat_cols:
            n_unique = df[self.cat_cols[0]].nunique() if len(self.cat_cols) == 1 else -1
            if len(self.cat_cols) == 1 and n_unique < 10:
                self.encoder = LabelEncoder()
                self.encoder.fit(df[self.cat_cols[0]].astype(str))
                self.log.append(f"{self.cat_cols[0]}: ìœ ë‹ˆí¬ê°’ {n_unique} < 10 â†’ LabelEncoding ì ìš©.")
            else:
                ohe_kwargs = dict(handle_unknown="ignore")
                if int(sklearn.__version__.split('.')[1]) >= 2:  # scikit-learn 1.2 ì´ìƒ
                    ohe_kwargs['sparse_output'] = False
                else:
                    ohe_kwargs['sparse'] = False
                self.encoder = OneHotEncoder(**ohe_kwargs)
                self.encoder.fit(df[self.cat_cols].astype(str))
                self.log.append(f"{', '.join(self.cat_cols)}: OneHotEncoding ì ìš© (ë²”ì£¼í˜• >1ê°œ ë˜ëŠ” ìœ ë‹ˆí¬ê°’ â‰¥10).")

        # 5. ì´ìƒì¹˜ ì²˜ë¦¬: IsolationForest ì ìš©, ì´ìƒì¹˜ row ì‹¤ì œ ì œê±° (í›ˆë ¨ì…‹ì—ì„œë§Œ)
        self.isolation_mask = np.ones(len(df), dtype=bool)  # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë‘ ì‚¬ìš©
        if len(df) > 200 and self.num_cols:
            iso = IsolationForest(n_estimators=40, contamination=0.01, random_state=42)
            out_pred = iso.fit_predict(num_filled)
            outlier_idx = np.where(out_pred == -1)[0]
            if len(outlier_idx) > 0:
                self.log.append(f"IsolationForestë¡œ {len(outlier_idx)}ê°œ row ì´ìƒì¹˜ ìë™ ì œê±°")
                self.isolation_mask[outlier_idx] = False  # ì´ìƒì¹˜ ë§ˆìŠ¤í¬ ì €ì¥
            else:
                self.log.append("IsolationForestë¡œ ì‹¬ê°í•œ ì´ìƒì¹˜ ì—†ìŒ.")
        else:
            self.log.append("í–‰ ê°œìˆ˜ ë¶€ì¡±/ìˆ˜ì¹˜í˜• ì—†ìŒ: ì´ìƒì¹˜ íƒì§€ ìƒëµ")

        # 6. í´ë˜ìŠ¤ imbalance ìë™ ë³´ì •: SMOTE(ì†Œìˆ˜ í´ë˜ìŠ¤ 10% ë¯¸ë§Œ/imbalance>4 ë°°)
        class_counts = df[target].value_counts()
        ratio = class_counts.max() / class_counts.min() if len(class_counts) > 1 else 1.0
        if ratio > 4 and class_counts.min() / len(df) < 0.1:
            self.smote_applied = True
            self.log.append(f"í´ë˜ìŠ¤ ë¶ˆê· í˜• ì‹¬ê° (ratio={ratio:.1f}) â†’ SMOTE(í•©ì„±ìƒ˜í”Œ) ì ìš© ì˜ˆì •")
        else:
            self.smote_applied = False
            self.log.append("í´ë˜ìŠ¤ ë¶„í¬ ê· í˜• ì–‘í˜¸ or ì‹¬ê°í•˜ì§€ ì•Šì•„ SMOTE ë¯¸ì ìš©")

        # 7. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
        classes = np.unique(df[target])
        weights = class_weight.compute_class_weight("balanced", classes=classes, y=df[target])
        self.class_weights = dict(zip(classes, weights))
        self.log.append(f"í´ë˜ìŠ¤ë³„ ìë™ ê°€ì¤‘ì¹˜ ë¶€ì—¬: {self.class_weights}")

    def transform(self, df, target):
        # ì´ìƒì¹˜ ë§ˆìŠ¤í¬ ì ìš© (train setì—ì„œë§Œ ì ìš©!)
        if self.isolation_mask is not None and len(self.isolation_mask) == len(df):
            df = df[self.isolation_mask]
        # 1. ê²°ì¸¡ì¹˜
        X_num = pd.DataFrame(self.imputer_num.transform(df[self.num_cols]), columns=self.num_cols, index=df.index)
        if self.cat_cols:
            X_cat = pd.DataFrame(self.imputer_cat.transform(df[self.cat_cols]), columns=self.cat_cols, index=df.index)
        else:
            X_cat = pd.DataFrame(index=df.index)
        # 2. ìŠ¤ì¼€ì¼ë§
        X_num_scaled = pd.DataFrame(self.scaler.transform(X_num), columns=self.num_cols, index=df.index)
        # 3. ì¸ì½”ë”©
        if self.encoder and self.cat_cols:
            if isinstance(self.encoder, LabelEncoder):
                X_cat_enc = pd.DataFrame({self.cat_cols[0]: self.encoder.transform(X_cat[self.cat_cols[0]].astype(str))}, index=df.index)
            else:
                X_cat_enc = pd.DataFrame(self.encoder.transform(X_cat), columns=self.encoder.get_feature_names_out(self.cat_cols), index=df.index)
            X = pd.concat([X_num_scaled, X_cat_enc], axis=1)
        else:
            X = X_num_scaled
        return X

    def fit_transform(self, df, target):
        self.fit(df, target)
        # isolation maskë¡œ ì´ìƒì¹˜ row ì œê±° (train set)
        df_clean = df[self.isolation_mask] if self.isolation_mask is not None and len(self.isolation_mask) == len(df) else df
        X = self.transform(df_clean, target)
        y = df_clean[target]
        # SMOTE ì ìš© (ì˜¤ì§ fit_transform(train)ì—ì„œë§Œ)
        if self.smote_applied:
            smote = SMOTE(random_state=42)
            X, y = smote.fit_resample(X, y)
            self.log.append(f"SMOTE ì ìš© í›„ ìƒ˜í”Œ ìˆ˜: {X.shape[0]}")
        return X, y

    def get_log(self):
        return self.log

def run(df, target, mode="fit_transform", preprocessor=None):
    if mode == "fit_transform":
        pre = ClassificationPreprocessor()
        X, y = pre.fit_transform(df, target)  # ì´ì œ X, y ë°˜í™˜
        st.header("âš¡ ì „ì²˜ë¦¬ ë‹¨ê³„ë³„ ì„¤ëª… (Train ê¸°ì¤€)")
        for step in pre.get_log():
            st.markdown(f"- {step}")
        st.subheader("ğŸ“‹ ì „ì²˜ë¦¬ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (Train)")
        st.write(X.head())
        st.write("ìµœì¢… shape:", X.shape)
        return X, y, pre
    elif mode == "transform" and preprocessor is not None:
        X = preprocessor.transform(df, target)
        st.header("âš¡ ì „ì²˜ë¦¬ ê²°ê³¼ (Valid/Test ê¸°ì¤€)")
        st.write("Trainì—ì„œ fitëœ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜(transform)ë§Œ ì ìš©")
        st.write(X.head())
        st.write("ìµœì¢… shape:", X.shape)
        return X
    else:
        raise ValueError("modeëŠ” fit_transform/transform ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•˜ê³ , transformì‹œ preprocessor í•„ìš”")