"""
ê³ ë„í™”ëœ Classification EDA (ìƒì—… AutoML ìˆ˜ì¤€)
------------------------------------------
- í´ë˜ìŠ¤ ë¶„í¬/imbalance, í´ë˜ìŠ¤ë³„ í†µê³„Â·ë¶„í¬ì°¨ ê²€ì •, ì£¼ìš” ë³€ìˆ˜ ì¤‘ìš”ë„/í•´ì„, ì´ìƒì¹˜, ë‹¤ì¤‘ê³µì„ ì„±, ì°¨ì›ì¶•ì†Œ, ë™ì  í•´ì„¤/ê²½ê³ 
- t-SNE/UMAP, violin/swarm/stacked bar, chi2/ANOVA, mutual_info ë“± í’€ì„¸íŠ¸
"""
from __future__ import annotations
import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats
from scipy.stats import chi2_contingency

try:
    import ydata_profiling
except ImportError:
    ydata_profiling = None
try:
    from sklearn.ensemble import IsolationForest
    from sklearn.neighbors import LocalOutlierFactor
except ImportError:
    IsolationForest = LocalOutlierFactor = None
try:
    from sklearn.manifold import TSNE
except ImportError:
    TSNE = None
try:
    from umap import UMAP
except ImportError:
    UMAP = None
try:
    from statsmodels.stats.outliers_influence import variance_inflation_factor as vif
except ImportError:
    vif = None

from sklearn.feature_selection import chi2, f_classif, mutual_info_classif
from imblearn.over_sampling import SMOTE

_SAMPLE_SIZE = 10000

@st.cache_data(show_spinner=False)
def sample_df(df: pd.DataFrame, max_rows=_SAMPLE_SIZE) -> pd.DataFrame:
    if len(df) > max_rows:
        return df.sample(n=max_rows, random_state=42)
    return df.copy()

def _overview(df: pd.DataFrame, eda_logs: list):
    st.subheader("0ï¸âƒ£ ë°ì´í„° ê°œìš”")
    col1, col2 = st.columns(2)
    with col1:
        st.write("í–‰/ì—´:", df.shape)
        st.write("ë°ì´í„° íƒ€ì…:", dict(df.dtypes.value_counts()))
        st.write("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰:", f"{df.memory_usage(deep=True).sum()/1e6:.2f} MB")
    with col2:
        st.write(df.head(5))
    msg = f"ë°ì´í„°: {df.shape[0]:,}ê°œ í–‰, {df.shape[1]}ê°œ ì»¬ëŸ¼, {dict(df.dtypes.value_counts())} íƒ€ì…."
    st.caption(msg)
    eda_logs.append(msg)

def _missing_and_duplicates(df: pd.DataFrame, target: str, eda_logs: list):
    st.subheader("1ï¸âƒ£ ê²°ì¸¡ & ì¤‘ë³µ (í´ë˜ìŠ¤ë³„ë„ í‘œì‹œ)")
    miss = df.isna().mean().sort_values(ascending=False)
    miss_by_class = df.groupby(target).apply(lambda x: x.isna().mean())
    dup_cnt = df.duplicated().sum()
    if miss.max() == 0:
        msg = "âœ… ê²°ì¸¡ì¹˜ ì—†ìŒ."
        st.success(msg)
        eda_logs.append(msg)
    else:
        fig, ax = plt.subplots(figsize=(6, 3))
        miss[miss > 0].plot.bar(ax=ax)
        ax.set_ylabel("Missing Ratio")
        st.pyplot(fig, use_container_width=True)
        st.write("í´ë˜ìŠ¤ë³„ ê²°ì¸¡ë¥ (ìƒìœ„ 5):")
        st.dataframe(miss_by_class.T.head(5))
        msg = f"ê²°ì¸¡ì¹˜ ìƒìœ„ ì»¬ëŸ¼: {', '.join(miss[miss>0].index[:3])}"
        eda_logs.append(msg)
    st.write("ğŸ” ì¤‘ë³µ í–‰:", dup_cnt)
    if dup_cnt > 0:
        cap = f"ì¤‘ë³µ ë°ì´í„° {dup_cnt}ê±´: ì œê±° ê¶Œì¥"
        st.caption(cap)
        eda_logs.append(cap)
    else:
        eda_logs.append("ì¤‘ë³µ ë°ì´í„° ì—†ìŒ.")

def _target_dist(df: pd.DataFrame, target: str, eda_logs: list):
    st.subheader("2ï¸âƒ£ í´ë˜ìŠ¤ ë¶„í¬ (Imbalance ìë™ ê²½ê³ Â·ëŒ€ì‘)")
    vc = df[target].value_counts(dropna=False)
    fig, ax = plt.subplots()
    vc.plot.bar(ax=ax, color=sns.color_palette('tab10', len(vc)))
    ax.set_ylabel("Count")
    ax.set_title("Target Class Distribution")
    st.pyplot(fig, use_container_width=True)
    st.write(vc.to_frame("Count").assign(ë¹„ìœ¨=lambda x: x["Count"]/x["Count"].sum()).T)
    imbalance_ratio = vc.max() / vc.min() if len(vc) > 1 and vc.min() > 0 else 1.0
    if imbalance_ratio > 4:
        msg = f"í´ë˜ìŠ¤ imbalance ì‹¬ê° (ìµœë‹¤/ìµœì†Œ ë¹„ìœ¨: {imbalance_ratio:.1f}) â†’ SMOTE ë“± ìƒ˜í”Œë§/ê°€ì¤‘ì¹˜ í•„ìš”"
        st.error(msg)
        eda_logs.append(msg)
    elif imbalance_ratio > 1.5:
        msg = f"í´ë˜ìŠ¤ imbalance ì£¼ì˜ (ìµœë‹¤/ìµœì†Œ ë¹„ìœ¨: {imbalance_ratio:.1f})"
        st.warning(msg)
        eda_logs.append(msg)
    else:
        msg = "í´ë˜ìŠ¤ ë¶„í¬ ê· í˜• ì–‘í˜¸"
        st.success(msg)
        eda_logs.append(msg)

def _classwise_stats(df: pd.DataFrame, target: str, eda_logs: list):
    st.subheader("3ï¸âƒ£ í´ë˜ìŠ¤ë³„ ê¸°ìˆ í†µê³„/ëŒ€í‘œê°’")
    classes = df[target].dropna().unique()
    num_cols = df.select_dtypes(include="number").columns
    stats_df = df.groupby(target)[num_cols].agg(['mean', 'std', 'min', 'max'])
    st.dataframe(stats_df)
    msg = f"í´ë˜ìŠ¤ë³„ ìˆ˜ì¹˜í˜• ëŒ€í‘œê°’, ì°¨ì´ í™•ì¸: ì£¼ìš” í”¼ì²˜ {list(num_cols)[:5]}"
    eda_logs.append(msg)
    # í´ë˜ìŠ¤ë³„ ëŒ€í‘œ ìƒ˜í”Œ
    for cls in classes:
        cls_df = df[df[target]==cls]
        median_vals = cls_df[num_cols].median()
        closest = ((cls_df[num_cols] - median_vals).abs().sum(axis=1)).idxmin()
        st.write(f"Class {cls} ëŒ€í‘œ ìƒ˜í”Œ:")
        st.write(cls_df.loc[[closest]])

def _categorical_eda(df: pd.DataFrame, target: str, eda_logs=None):
    cat_cols = [col for col in df.select_dtypes(include=['object', 'category']).columns if col != target]
    if not cat_cols: return
    st.subheader("4ï¸âƒ£ ì£¼ìš” ë²”ì£¼í˜• ë³€ìˆ˜ ë¶„í¬/í´ë˜ìŠ¤ë³„ ì°¨ì´(ì¹´ì´ì œê³±)")
    for col in cat_cols:
        fig, ax = plt.subplots()
        ct = pd.crosstab(df[col], df[target])
        ct.plot(kind="bar", stacked=True, ax=ax)
        ax.set_title(f"{col} by {target}")
        st.pyplot(fig, use_container_width=True)
        st.write(ct)
        # chi2 ë…ë¦½ì„± ê²€ì •
        chi2_val, p, dof, expected = chi2_contingency(ct.values)
        if isinstance(p, (np.ndarray, list)):  # pê°€ ë°°ì—´ì´ë©´ ì²« ë²ˆì§¸ ê°’ë§Œ ì‚¬ìš©
            p_val = float(np.asarray(p).flat[0])
        else:
            p_val = float(p)
        if p_val < 0.05:
            st.warning(f"{col}: í´ë˜ìŠ¤ë³„ ë¶„í¬ ì°¨ì´ ìœ ì˜í•¨ (chi2, p={p_val:.4f})")
            if eda_logs is not None:
                eda_logs.append(f"{col}: í´ë˜ìŠ¤ë³„ ë¶„í¬ ì°¨ì´ ìœ ì˜ (chi2, p={p_val:.4f})")
        else:
            st.info(f"{col}: ë¶„í¬ ì°¨ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•˜ì§€ ì•ŠìŒ (p={p_val:.4f})")
            if eda_logs is not None:
                eda_logs.append(f"{col}: ë¶„í¬ ì°¨ì´ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ (chi2, p={p_val:.4f})")

def _num_feature_by_class(df: pd.DataFrame, target: str, eda_logs: list, top_k=5):
    st.subheader("5ï¸âƒ£ ì£¼ìš” ìˆ˜ì¹˜í˜• í”¼ì²˜ë³„ í´ë˜ìŠ¤ê°„ ë¶„í¬/ì°¨ì´(ANOVA/violin/swarm)")
    num_cols = [c for c in df.select_dtypes(include='number').columns if c != target]
    if len(num_cols) == 0:
        return
    scores, pvals = f_classif(df[num_cols].fillna(0), df[target])
    imp = pd.Series(scores, index=num_cols)
    top_cols = imp.sort_values(ascending=False).head(top_k).index
    for col in top_cols:
        fig, ax = plt.subplots()
        sns.violinplot(x=df[target], y=df[col], ax=ax, inner="quartile", palette="pastel")
        sns.swarmplot(x=df[target], y=df[col], color="k", size=2, ax=ax)
        ax.set_title(f"{col} by {target} (F={imp[col]:.2f}, p={pvals[list(num_cols).index(col)]:.4f})")
        st.pyplot(fig, use_container_width=True)
        if pvals[list(num_cols).index(col)] < 0.05:
            msg = f"{col}: í´ë˜ìŠ¤ê°„ ë¶„í¬ ì°¨ì´ ìœ ì˜ (ANOVA p={pvals[list(num_cols).index(col)]:.4f})"
            st.warning(msg)
        else:
            msg = f"{col}: ë¶„í¬ ì°¨ì´ ìœ ì˜í•˜ì§€ ì•ŠìŒ (p={pvals[list(num_cols).index(col)]:.4f})"
            st.info(msg)
        eda_logs.append(msg)

def _feature_importance(df: pd.DataFrame, target: str, eda_logs: list, top_k=10):
    st.subheader("6ï¸âƒ£ Feature Importance Preview (ì •ë³´ì´ë“ ê¸°ë°˜)")
    num_cols = [c for c in df.select_dtypes(include='number').columns if c != target]
    if len(num_cols) == 0: return
    X = df[num_cols].fillna(0)
    y = df[target]
    mi = mutual_info_classif(X, y, discrete_features=False)
    imp = pd.Series(mi, index=num_cols).sort_values(ascending=False)
    fig, ax = plt.subplots()
    imp.head(top_k).plot.bar(ax=ax)
    ax.set_title("Mutual Information Top Features")
    st.pyplot(fig, use_container_width=True)
    msg = "ìƒìœ„ ì¤‘ìš” ë³€ìˆ˜: " + ", ".join(imp.head(top_k).index)
    st.write(msg)
    eda_logs.append(msg)

def _outlier_overview(df: pd.DataFrame, target: str, eda_logs: list):
    num_cols = df.select_dtypes(include="number").columns
    if not num_cols.any():
        return
    st.subheader("7ï¸âƒ£ ì´ìƒì¹˜ íƒìƒ‰ (ìˆ˜ì¹˜í˜• ê¸°ì¤€)")
    sample = sample_df(df[num_cols])
    outlier_ratio = {}
    for col in num_cols:
        q1, q3 = np.percentile(sample[col].dropna(), [25, 75])
        iqr = q3 - q1
        lower, upper = q1 - 1.5 * iqr, q3 + 1.5 * iqr
        mask = (sample[col] < lower) | (sample[col] > upper)
        outlier_ratio[col] = mask.mean()
    sr = pd.Series(outlier_ratio).sort_values(ascending=False)
    fig, ax = plt.subplots(figsize=(6, 3))
    sr.plot.bar(ax=ax)
    ax.set_ylabel("IQR Outlier Ratio")
    st.pyplot(fig, use_container_width=True)
    high_outlier = sr[sr > 0.05]
    if not high_outlier.empty:
        msg = "ì´ìƒì¹˜ ë¹„ìœ¨ 5%â†‘: " + ', '.join([f"{col}({ratio:.1%})" for col, ratio in high_outlier.items()])
        st.warning(msg)
    else:
        msg = "ëª¨ë“  ë³€ìˆ˜ ì´ìƒì¹˜ ë¹„ìœ¨ 5% ë¯¸ë§Œ"
        st.success(msg)
    eda_logs.append(msg)
    # ì´ìƒì¹˜ ë§ì€ í´ë˜ìŠ¤/ìƒ˜í”Œ í•˜ì´ë¼ì´íŠ¸
    st.write("ì´ìƒì¹˜ Top 5 ìƒ˜í”Œ:")
    z = np.abs(stats.zscore(df[num_cols].fillna(0)))
    outlier_idx = np.where((z > 3).any(axis=1))[0][:5]
    st.write(df.iloc[outlier_idx])

def _multicollinearity_vif(df: pd.DataFrame, eda_logs: list):
    num_df = df.select_dtypes(include="number").dropna()
    if vif is None or num_df.shape[1] < 2:
        return
    st.subheader("8ï¸âƒ£ ë‹¤ì¤‘ê³µì„ ì„±(VIF)")
    sample = sample_df(num_df)
    X = sample.values
    vif_vals = [vif(X, i) for i in range(X.shape[1])]
    res = pd.DataFrame({
        "feature": num_df.columns,
        "VIF": vif_vals
    }).sort_values("VIF", ascending=False)
    st.dataframe(res, use_container_width=True)
    high_vif = res[res["VIF"] > 10]
    if not high_vif.empty:
        msg = "VIF>10: " + ', '.join(high_vif['feature'].tolist())
        st.warning(msg)
        eda_logs.append(msg)
    else:
        msg = "VIF<10: ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œ ì—†ìŒ"
        st.success(msg)
        eda_logs.append(msg)

def _correlation(df: pd.DataFrame, eda_logs: list):
    num_df = df.select_dtypes(include="number")
    if num_df.shape[1] < 2:
        return
    st.subheader("9ï¸âƒ£ ìƒê´€ í–‰ë ¬(Pearson)")
    corr = num_df.corr()
    fig, ax = plt.subplots(figsize=(min(12, 0.5 * corr.shape[1]), 8))
    sns.heatmap(corr, cmap="coolwarm", center=0, ax=ax)
    st.pyplot(fig, use_container_width=True)
    high_pairs = [
        (i, j)
        for i in corr.columns
        for j in corr.columns
        if i != j and abs(corr.loc[i, j]) > 0.8
    ]
    if high_pairs:
        msg = "ìƒê´€ |r| > .8 ë³€ìˆ˜ìŒ: " + ", ".join([f"{a}-{b}" for a, b in high_pairs])
        st.warning(msg)
        eda_logs.append(msg)
    else:
        msg = "ëª¨ë“  ë³€ìˆ˜ ìŒì—ì„œ |r| > .8 ì—†ìŒ"
        st.success(msg)
        eda_logs.append(msg)

def _dim_reduction(df: pd.DataFrame, target: str,eda_logs: list):
    st.subheader("ğŸ”Ÿ ì°¨ì› ì¶•ì†Œ(t-SNE/UMAP/Pairplot) ì‹œê°í™”")
    num_cols = [c for c in df.select_dtypes(include='number').columns if c != target]
    if len(num_cols) < 2: return
    msg = "ì°¨ì›ì¶•ì†Œ/ì‹œê°í™” ì‹¤í–‰"
    eda_logs.append(msg)
    X = df[num_cols].fillna(0)
    y = df[target]
    if TSNE is not None:
        tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(X)//10))
        X_emb = tsne.fit_transform(X)
        df_emb = pd.DataFrame(X_emb, columns=["x", "y"])
        df_emb[target] = y.values
        fig, ax = plt.subplots()
        sns.scatterplot(x="x", y="y", hue=target, data=df_emb, ax=ax, palette='tab10', alpha=0.8)
        ax.set_title("t-SNE Embedding by Class")
        st.pyplot(fig, use_container_width=True)
    if UMAP is not None:
        reducer = UMAP(n_components=2, random_state=42)
        X_emb = reducer.fit_transform(X)
        df_emb = pd.DataFrame(X_emb, columns=["x", "y"])
        df_emb[target] = y.values
        fig, ax = plt.subplots()
        sns.scatterplot(x="x", y="y", hue=target, data=df_emb, ax=ax, palette='tab10', alpha=0.8)
        ax.set_title("UMAP Embedding by Class")
        st.pyplot(fig, use_container_width=True)
    # Pairplot (ë¹„ì„ í˜•/ë³µì¡ íŒ¨í„´ í™•ì¸)
    if len(num_cols) <= 8:
        st.write("ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì¡°í•©ë³„ pairplot:")
        pairplot_fig = sns.pairplot(df, hue=target, vars=num_cols, palette='tab10', plot_kws={"alpha":0.5, "s":20})
        st.pyplot(pairplot_fig)

def _full_profile(df: pd.DataFrame):
    with st.expander("ğŸ” ì „ì²´ Profiling Report (optional)", expanded=False):
        st.info("ì „ì²´ ë³€ìˆ˜Â·ê´€ê³„Â·ë¶„í¬ ì¼ê´„ ì§„ë‹¨(ëŒ€ìš©ëŸ‰ ë°ì´í„°ëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)")
        if ydata_profiling:
            profile = ydata_profiling.ProfileReport(df, title="Profiling", minimal=True)
            st.components.v1.html(profile.to_html(), height=800, scrolling=True)
        else:
            st.info("`pip install ydata-profiling` í›„ ì „ì²´ ë¦¬í¬íŠ¸ ê°€ëŠ¥")

def generate(df: pd.DataFrame, target: str):
    """
    Streamlit ìë™ EDA + ê²°ê³¼ë³„ ë™ì  í•´ì„¤ (Classification)
    """
    df = sample_df(df)
    eda_logs = []
    _overview(df, eda_logs)
    _missing_and_duplicates(df, target, eda_logs)
    _target_dist(df, target, eda_logs)
    _classwise_stats(df, target, eda_logs)
    _categorical_eda(df, target, eda_logs)
    _num_feature_by_class(df, target, eda_logs)
    _feature_importance(df, target, eda_logs)
    _outlier_overview(df, target, eda_logs)
    _multicollinearity_vif(df, eda_logs)
    _correlation(df, eda_logs)
    _dim_reduction(df, target, eda_logs)
    _full_profile(df)
    return eda_logs 