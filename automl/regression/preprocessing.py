import streamlit as st
import numpy as np
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, LabelEncoder
from statsmodels.stats.outliers_influence import variance_inflation_factor

class Preprocessor:
    def __init__(self):
        self.imputer = None
        self.scaler = None
        self.encoder = None
        self.num_cols = []
        self.cat_cols = []
        self.selected_columns = []
        self.vif_threshold = 10
        self.log = []

    def fit(self, df, target):
        self.log.clear()
        # 1. ì»¬ëŸ¼ ë¶„ë¦¬
        self.num_cols = [col for col in df.select_dtypes(include='number').columns if col != target]
        self.cat_cols = list(df.select_dtypes(include=['object', 'category']).columns)

        # 2. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìˆ˜ì¹˜í˜•: í‰ê· /ì¤‘ì•™ê°’, ë²”ì£¼í˜•: ìµœë¹ˆê°’)
        for col in self.num_cols:
            null_ratio = df[col].isna().mean()
            if null_ratio == 0:
                continue
            if null_ratio < 0.3:
                strategy = "mean"
                why = f"{col} ê²°ì¸¡ì¹˜ ë¹„ìœ¨ {null_ratio:.1%}: 30% ë¯¸ë§Œ â†’ í‰ê· (mean)ìœ¼ë¡œ ëŒ€ì¹˜."
            else:
                strategy = "median"
                why = f"{col} ê²°ì¸¡ì¹˜ ë¹„ìœ¨ {null_ratio:.1%}: 30% ì´ìƒ â†’ ì¤‘ì•™ê°’(median)ìœ¼ë¡œ ëŒ€ì¹˜."
            self.log.append(why)
        self.imputer = SimpleImputer(strategy="mean")
        self.imputer.fit(df[self.num_cols])
        self.log.append("ìˆ˜ì¹˜í˜• ê²°ì¸¡ì¹˜ëŠ” scikit-learn SimpleImputerë¡œ ì¼ê´„ ëŒ€ì¹˜ (strategy=mean).")

        # 3. ìŠ¤ì¼€ì¼ë§: Skewnessì— ë”°ë¼ ê²°ì •
        skewness = np.abs(df[self.num_cols].skew()).mean() if self.num_cols else 0
        if skewness < 1:
            self.scaler = StandardScaler()
            self.log.append(f"í‰ê·  Skewness {skewness:.2f}: 1 ë¯¸ë§Œ â†’ StandardScaler ì ìš© (ì •ê·œë¶„í¬ ê°€ì •).")
        else:
            self.scaler = RobustScaler()
            self.log.append(f"í‰ê·  Skewness {skewness:.2f}: 1 ì´ìƒ â†’ RobustScaler ì ìš© (ì´ìƒì¹˜ ì˜í–¥ ìµœì†Œí™”).")
        X_num = self.imputer.transform(df[self.num_cols])
        self.scaler.fit(X_num)

        # 4. ì¸ì½”ë”©
        if self.cat_cols:
            n_unique = df[self.cat_cols[0]].nunique() if len(self.cat_cols) == 1 else -1
            if len(self.cat_cols) == 1 and n_unique < 10:
                self.encoder = LabelEncoder()
                self.encoder.fit(df[self.cat_cols[0]])
                self.log.append(f"{self.cat_cols[0]}: ìœ ë‹ˆí¬ê°’ {n_unique} < 10 â†’ LabelEncoding ì ìš©.")
            else:
                self.encoder = OneHotEncoder(handle_unknown="ignore", sparse=False)
                self.encoder.fit(df[self.cat_cols])
                self.log.append(f"{', '.join(self.cat_cols)}: OneHotEncoding ì ìš© (ë²”ì£¼í˜• >1ê°œ ë˜ëŠ” ìœ ë‹ˆí¬ê°’ â‰¥10).")
        else:
            self.encoder = None
            self.log.append("ë²”ì£¼í˜• ë³€ìˆ˜ ì—†ìŒ â†’ ì¸ì½”ë”© ìƒëµ.")

        # 5. ë‹¤ì¤‘ê³µì„ ì„±(VIF) ì œê±° (train ê¸°ì¤€)
        X_num_scaled = self.scaler.transform(X_num)
        vif_data = pd.DataFrame(X_num_scaled, columns=self.num_cols)
        vifs = [variance_inflation_factor(vif_data.values, i) for i in range(len(self.num_cols))]
        self.selected_columns = [col for col, v in zip(self.num_cols, vifs) if v < self.vif_threshold]
        dropped = [col for col, v in zip(self.num_cols, vifs) if v >= self.vif_threshold]
        for col, v in zip(self.num_cols, vifs):
            if v >= self.vif_threshold:
                self.log.append(f"{col}: VIF={v:.1f} > 10 â†’ ë‹¤ì¤‘ê³µì„ ì„± ë†’ì•„ ìë™ ì œê±°.")
            else:
                self.log.append(f"{col}: VIF={v:.1f} < 10 â†’ ìœ ì§€.")
        if dropped:
            self.log.append(f"VIF 10â†‘ ì»¬ëŸ¼ ìë™ ì œê±°: {', '.join(dropped)}")
        else:
            self.log.append("VIF 10â†‘ ì»¬ëŸ¼ ì—†ìŒ â†’ ì „ë¶€ ì‚¬ìš©.")

    def transform(self, df, target):
        X_num = pd.DataFrame(self.imputer.transform(df[self.num_cols]), columns=self.num_cols, index=df.index)
        X_num_scaled = pd.DataFrame(self.scaler.transform(X_num), columns=self.num_cols, index=df.index)
        if self.encoder and self.cat_cols:
            # LabelEncoderì™€ OneHotEncoder ë¶„ê¸°
            if isinstance(self.encoder, LabelEncoder):
                X_cat = pd.DataFrame({self.cat_cols[0]: self.encoder.transform(df[self.cat_cols[0]])}, index=df.index)
            else:
                X_cat = pd.DataFrame(self.encoder.transform(df[self.cat_cols]), 
                                     columns=self.encoder.get_feature_names_out(self.cat_cols), index=df.index)
            X = pd.concat([X_num_scaled, X_cat], axis=1)
        else:
            X = X_num_scaled
        # VIF ê¸°ë°˜ feature ì„ íƒ
        X = X[self.selected_columns + [c for c in X.columns if c not in self.selected_columns]]
        return X

    def fit_transform(self, df, target):
        self.fit(df, target)
        return self.transform(df, target)

    def get_log(self):
        return self.log

def run(df, target, mode="fit_transform", preprocessor=None):
    if mode == "fit_transform":
        pre = Preprocessor()
        X = pre.fit_transform(df, target)
        st.header("âš¡ ì „ì²˜ë¦¬ ë‹¨ê³„ë³„ ì„¤ëª… (Train ê¸°ì¤€)")
        for step in pre.get_log():
            st.markdown(f"- {step}")
        st.subheader("ğŸ“‹ ì „ì²˜ë¦¬ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (Train)")
        st.write(X.head())
        st.write("ìµœì¢… shape:", X.shape)
        return X, pre
    elif mode == "transform" and preprocessor is not None:
        X = preprocessor.transform(df, target)
        st.header("âš¡ ì „ì²˜ë¦¬ ê²°ê³¼ (Valid/Test ê¸°ì¤€)")
        st.write("Trainì—ì„œ fitëœ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜(transform)ë§Œ ì ìš©")
        st.write(X.head())
        st.write("ìµœì¢… shape:", X.shape)
        return X
    else:
        raise ValueError("modeëŠ” fit_transform/transform ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•˜ê³ , transformì‹œ preprocessor í•„ìš”")