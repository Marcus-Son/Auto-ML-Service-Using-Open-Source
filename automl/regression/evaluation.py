import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error
from sklearn.inspection import permutation_importance

# SHAP ë° LIME ë“± XAI
try:
    import shap
except ImportError:
    shap = None

def regression_metrics(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    return {
        "MSE": mse,
        "RMSE": np.sqrt(mse),
        "MAE": mean_absolute_error(y_true, y_pred),
        "MAPE": mean_absolute_percentage_error(y_true, y_pred),
        "R2": r2_score(y_true, y_pred)
    }

def show_metrics(y_true, y_pred):
    st.subheader("ğŸ“Š ì„±ëŠ¥ ì§€í‘œ (Test Set)")
    metrics = regression_metrics(y_true, y_pred)
    st.write({k: f"{v:.4f}" for k, v in metrics.items()})

    # í•´ì„¤ ì˜ˆì‹œ
    st.markdown(f"""
    - **MSE** (í‰ê· ì œê³±ì˜¤ì°¨): ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
    - **MAE** (í‰ê· ì ˆëŒ€ì˜¤ì°¨): ì‹¤ì œ ì˜¤ì°¨ì˜ í‰ê· . í•´ì„ì´ ì§ê´€ì 
    - **RMSE**: MSEì™€ ìœ ì‚¬, ì´ìƒì¹˜ì— ë¯¼ê°
    - **MAPE**: ì˜ˆì¸¡ê°’/ì‹¤ì œê°’ ë¹„ìœ¨ë¡œ ì§ê´€ì  ì •í™•ë„
    - **R2**: 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ (ì„¤ëª…ë ¥)
    """)

def plot_residuals(y_true, y_pred):
    st.subheader("ğŸ“‰ ì”ì°¨(Residuals) ë¶„ì„")
    residuals = y_true - y_pred
    fig, axs = plt.subplots(1, 2, figsize=(12,4))
    sns.scatterplot(x=y_pred, y=residuals, ax=axs[0])
    axs[0].axhline(0, color='red', linestyle='--')
    axs[0].set_title("ì˜ˆì¸¡ê°’ vs ì”ì°¨")
    axs[0].set_xlabel("ì˜ˆì¸¡ê°’")
    axs[0].set_ylabel("ì”ì°¨")
    sns.histplot(residuals, kde=True, ax=axs[1])
    axs[1].set_title("ì”ì°¨ ë¶„í¬")
    st.pyplot(fig)

def plot_feature_importance(model, X_test):
    st.subheader("ğŸ§‘â€ğŸ”¬ Permutation Feature Importance (PFI)")
    try:
        result = permutation_importance(model, X_test, model.predict(X_test), n_repeats=20, random_state=42)
        importance = pd.Series(result.importances_mean, index=X_test.columns)
        topk = importance.abs().sort_values(ascending=False).head(15)
        fig, ax = plt.subplots()
        topk.plot.barh(ax=ax)
        ax.set_title("Permutation Feature Importance (ìƒìœ„ 15)")
        st.pyplot(fig)
    except Exception as e:
        st.warning(f"Permutation Importance ê³„ì‚° ì‹¤íŒ¨: {e}")

def plot_shap(model, X_test):
    st.subheader("ğŸ” SHAP Explainability")
    if shap is None:
        st.info("SHAP ì„¤ì¹˜ í•„ìš”: `pip install shap`")
        return
    try:
        explainer = shap.Explainer(model, X_test)
        shap_values = explainer(X_test)
        st.info("ìƒì—… AutoMLì—ì„œë„ ê°€ì¥ ìì£¼ ì“°ì´ëŠ” ì „ì²´/ê°œë³„ ì˜ˆì¸¡ í•´ì„")
        fig1 = shap.plots.beeswarm(shap_values, show=False)
        st.pyplot(bbox_inches='tight', pad_inches=0)
        st.markdown("**SHAP summary plot:** ì „ì²´ feature ì˜í–¥ë ¥")
        st.pyplot(fig1)
        st.markdown("---")
        idx = st.slider("ê°œë³„ ì˜ˆì¸¡ ìƒ˜í”Œ(index)", 0, X_test.shape[0]-1, 0)
        st.markdown("**ê°œë³„ ì˜ˆì¸¡ SHAP force plot**")
        fig2 = shap.plots.force(shap_values[idx], matplotlib=True, show=False)
        st.pyplot(fig2)
    except Exception as e:
        st.warning(f"SHAP ì„¤ëª… ì‹¤íŒ¨: {e}")

def plot_predicted_vs_actual(y_true, y_pred):
    st.subheader("ğŸ“ˆ ì˜ˆì¸¡ê°’ vs ì‹¤ì œê°’ ì‚°ì ë„")
    fig, ax = plt.subplots()
    sns.scatterplot(x=y_true, y=y_pred, ax=ax)
    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')
    ax.set_xlabel("ì‹¤ì œê°’")
    ax.set_ylabel("ì˜ˆì¸¡ê°’")
    ax.set_title("ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’")
    st.pyplot(fig)

def advanced_evaluation(model, X_test, y_test):
    # ì „í†µì  ì„±ëŠ¥ì§€í‘œ
    y_pred = model.predict(X_test)
    show_metrics(y_test, y_pred)
    plot_predicted_vs_actual(y_test, y_pred)
    plot_residuals(y_test, y_pred)
    plot_feature_importance(model, X_test)
    plot_shap(model, X_test)

    # ìƒì—… AutoMLì‹ ë¦¬í¬íŠ¸ ì•ˆë‚´
    st.markdown("""
    ---
    ## ìƒì—… AutoML ì„œë¹„ìŠ¤ ë¦¬í¬íŠ¸ ìŠ¤íƒ€ì¼
    - **ì—ëŸ¬ ë¶„ì„**: ì´ìƒì¹˜ ìƒ˜í”Œ ìë™ íƒì§€/í‘œì‹œ (ì•„ë˜ í‘œ)
    - **ì˜ˆì¸¡ ì‹ ë¢°êµ¬ê°„(Confidence Interval)**: (ì´ë¡ ì /ì¶”ì •ì¹˜, ì¶”ê°€ êµ¬í˜„ ê°€ëŠ¥)
    - **Top N ì¤‘ìš” feature** + ìë™ í•´ì„ ì½”ë©˜íŠ¸
    - **ì „ì²´ ìš”ì•½ PDF/HTML ì €ì¥ (Streamlit ë‚´ ì¶”ê°€ êµ¬í˜„ ê°€ëŠ¥)**
    """)

    # ì´ìƒì¹˜ ì˜ˆì‹œ
    st.subheader("ì—ëŸ¬ê°€ í° ìƒ˜í”Œ Top 5")
    errors = np.abs(y_test - y_pred)
    top_idx = np.argsort(-errors)[:5]
    st.write(pd.DataFrame({
        "ì‹¤ì œê°’": y_test.iloc[top_idx].values,
        "ì˜ˆì¸¡ê°’": y_pred[top_idx],
        "ì—ëŸ¬": errors.iloc[top_idx]
    }))

    # (ì¶”ê°€ë¡œ: PDF/HTML ë¦¬í¬íŠ¸, Confidence Interval, Counterfactual ë“± ê°€ëŠ¥)


# ----- Main API -----
def evaluate(model, X_test, y_test):
    """ìƒì—… AutoML ìŠ¤íƒ€ì¼ íšŒê·€ í‰ê°€+XAI"""
    advanced_evaluation(model, X_test, y_test)